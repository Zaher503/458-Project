{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284d904b-e005-4375-a8db-e5b602aa42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2798acf1-f9f5-44ea-9705-6a20d8f95ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress TensorFlow logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "def build_price_awareness_model(input_shape):\n",
    "    \"\"\"\n",
    "    Defines the Keras Sequential model architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer and first hidden layer\n",
    "    # 'relu' activation is standard for hidden layers\n",
    "    model.add(Dense(128, input_dim=input_shape, activation='relu'))\n",
    "    \n",
    "    # Dropout layer to prevent overfitting\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Second hidden layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    # Third hidden layer\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    # A single neuron with no activation (or 'linear') for regression\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compile the model\n",
    "    # We use Mean Squared Error for loss as is standard for regression\n",
    "    # The Adam optimizer is a good, robust default\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164c3756-daa6-4500-84cd-175cfd69bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (7827, 493)\n",
      "Data shape after dropping NaNs: (7186, 493)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\mambaforge\\envs\\456\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">177,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m177,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,777</span> (733.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,777\u001b[0m (733.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,777</span> (733.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m187,777\u001b[0m (733.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n",
      "Epoch 1/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 398059339776.0000 - val_loss: 367835021312.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 326543998976.0000 - val_loss: 121701425152.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95643287552.0000 - val_loss: 103062773760.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 91230240768.0000 - val_loss: 94910595072.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107720392704.0000 - val_loss: 89442598912.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88208596992.0000 - val_loss: 85834244096.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78490763264.0000 - val_loss: 82954600448.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83638214656.0000 - val_loss: 80863698944.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74825957376.0000 - val_loss: 79057788928.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81134059520.0000 - val_loss: 77186285568.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80147087360.0000 - val_loss: 75672059904.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77456146432.0000 - val_loss: 74519298048.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77134856192.0000 - val_loss: 73368182784.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73853100032.0000 - val_loss: 72270561280.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69078065152.0000 - val_loss: 71381041152.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70484090880.0000 - val_loss: 70514663424.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61847568384.0000 - val_loss: 69588787200.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70580109312.0000 - val_loss: 68939415552.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70170714112.0000 - val_loss: 68075491328.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73884295168.0000 - val_loss: 67327930368.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60511940608.0000 - val_loss: 66930282496.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65984536576.0000 - val_loss: 66156408832.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72544714752.0000 - val_loss: 65650221056.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62879338496.0000 - val_loss: 65446252544.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58293039104.0000 - val_loss: 65278263296.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69304139776.0000 - val_loss: 64146169856.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58286063616.0000 - val_loss: 63854981120.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53527044096.0000 - val_loss: 64419405824.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68549083136.0000 - val_loss: 63033131008.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62344372224.0000 - val_loss: 62826807296.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65472724992.0000 - val_loss: 62645174272.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56767066112.0000 - val_loss: 62206619648.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73111437312.0000 - val_loss: 61854695424.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67320373248.0000 - val_loss: 61742632960.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68905418752.0000 - val_loss: 61408251904.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64225034240.0000 - val_loss: 61210169344.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63076233216.0000 - val_loss: 61140619264.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62588690432.0000 - val_loss: 61267714048.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59642630144.0000 - val_loss: 60549566464.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61738745856.0000 - val_loss: 60464078848.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52546248704.0000 - val_loss: 60562804736.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53491310592.0000 - val_loss: 60847321088.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71921385472.0000 - val_loss: 59947245568.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55907012608.0000 - val_loss: 60100259840.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63214895104.0000 - val_loss: 60064137216.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62588747776.0000 - val_loss: 59764908032.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60810944512.0000 - val_loss: 60358410240.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51923529728.0000 - val_loss: 59498733568.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55714992128.0000 - val_loss: 59869290496.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57612623872.0000 - val_loss: 59334180864.0000\n",
      "Training complete.\n",
      "\n",
      "Model evaluated on test set.\n",
      "Test Mean Squared Error (Loss): 59334180864.00\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test Mean Absolute Error (MAE): $151704.92\n",
      "\n",
      "Running an example prediction...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "Example Region Features (Unscaled, combined):\n",
      "SizeRank_zhvi                           1442.000000\n",
      "latest_rent                             1723.152805\n",
      "crime_rate_per_100000                    147.640674\n",
      "population                            854778.000000\n",
      "CountySchoolScore_y                       18.877410\n",
      "                                          ...      \n",
      "CountyName_zhvi_Yellowstone County         0.000000\n",
      "CountyName_zhvi_Yolo County                0.000000\n",
      "CountyName_zhvi_York County                0.000000\n",
      "CountyName_zhvi_Yuba County                0.000000\n",
      "CountyName_zhvi_Yuma County                0.000000\n",
      "Name: 1315, Length: 1385, dtype: float64\n",
      "\n",
      "Predicted Price: $448,111.91\n",
      "Actual Price: $629,822.75\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # --- 1. Data Ingestion ---\n",
    "    try:\n",
    "        # Load the core 8000-line CSV dataset\n",
    "        data = pd.read_csv('final_with_proficiency.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: '8000_listings.csv' not found.\")\n",
    "        print(\"Please create a mock CSV or update the file path.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Preprocessing ---\n",
    "    \n",
    "    # This dataset contains rich time-series data (e.g., '1/31/2000'),\n",
    "    # crime data, and school data. For this PoC, we will predict\n",
    "    # the 'latest_home_value' based on a mix of demographic,\n",
    "    # crime, school, and rent features.\n",
    "    \n",
    "    # Define features (X) and target (y)\n",
    "    # TODO: You can add/remove features here to experiment.\n",
    "    \n",
    "    # We must separate categorical and numerical features for preprocessing\n",
    "    categorical_features = ['STATE', 'Metro_zhvi', 'CountyName_zhvi']\n",
    "    numerical_features = [\n",
    "        'SizeRank_zhvi', 'latest_rent', 'crime_rate_per_100000', \n",
    "        'population', 'CountySchoolScore_y', 'Proficiency'\n",
    "    ]\n",
    "    target = 'latest_home_value'\n",
    "    \n",
    "    all_features = categorical_features + numerical_features\n",
    "    \n",
    "    # --- 2a. Handle Missing Data ---\n",
    "    # Ensure all our target rows and feature rows have data\n",
    "    try:\n",
    "        # Check for columns\n",
    "        if target not in data.columns or not all(f in data.columns for f in all_features):\n",
    "            print(f\"Error: CSV is missing one or more required columns.\")\n",
    "            print(f\"Needed: {all_features + [target]}\")\n",
    "            return\n",
    "        \n",
    "        # Drop rows where any of our selected columns are NaN\n",
    "        print(f\"Original data shape: {data.shape}\")\n",
    "        data.dropna(subset=all_features + [target], inplace=True)\n",
    "        print(f\"Data shape after dropping NaNs: {data.shape}\")\n",
    "        \n",
    "        if data.shape[0] == 0:\n",
    "            print(\"Error: No data remaining after dropping NaNs. Check your columns or data file.\")\n",
    "            return\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2b. One-Hot Encode Categorical Features ---\n",
    "    # This converts text (like 'CA') into numerical format for the model\n",
    "    X_categorical = pd.get_dummies(data[categorical_features], drop_first=True, dtype=int)\n",
    "    \n",
    "    # --- 2c. Combine Features ---\n",
    "    X_numerical = data[numerical_features]\n",
    "    \n",
    "    # Reset index to ensure clean concatenation\n",
    "    X_numerical.reset_index(drop=True, inplace=True)\n",
    "    X_categorical.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    X = pd.concat([X_numerical, X_categorical], axis=1)\n",
    "    y = data[target].values\n",
    "\n",
    "    # --- 3. Train/Test Split ---\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- 4. Feature Scaling ---\n",
    "    # This is CRITICAL for neural networks\n",
    "    # We scale ALL features (numerical and one-hot encoded)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # --- 5. Model Definition ---\n",
    "    input_shape = X_train_scaled.shape[1]\n",
    "    model = build_price_awareness_model(input_shape)\n",
    "    model.summary()\n",
    "\n",
    "    # --- 6. Model Training ---\n",
    "    print(\"\\nStarting model training...\")\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        epochs=50,       # Number of passes through the data\n",
    "        batch_size=32,   # Number of samples per update\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # --- 7. Model Evaluation ---\n",
    "    test_loss = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    print(f\"\\nModel evaluated on test set.\")\n",
    "    print(f\"Test Mean Squared Error (Loss): {test_loss:.2f}\")\n",
    "    \n",
    "    # Calculate Mean Absolute Error (MAE) for a more interpretable result\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mae = np.mean(np.abs(y_pred.flatten() - y_test))\n",
    "    print(f\"Test Mean Absolute Error (MAE): ${mae:.2f}\")\n",
    "\n",
    "    # --- 8. Example Prediction ---\n",
    "    print(\"\\nRunning an example prediction...\")\n",
    "    # We use the pandas-based X_test (before scaling) to show readable features\n",
    "    # Note: Column names will be slightly different after get_dummies\n",
    "    example_home_features_unscaled = X_test.iloc[0]\n",
    "    \n",
    "    # We use the scaled numpy array for the actual prediction\n",
    "    example_home_features_scaled = X_test_scaled[0].reshape(1, -1)\n",
    "    \n",
    "    predicted_price = model.predict(example_home_features_scaled)[0][0]\n",
    "    actual_price = y_test[0]\n",
    "    \n",
    "    print(\"\\nExample Region Features (Unscaled, combined):\")\n",
    "    print(example_home_features_unscaled)\n",
    "    print(f\"\\nPredicted Price: ${predicted_price:,.2f}\")\n",
    "    print(f\"Actual Price: ${actual_price:,.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081b7417-b46e-41be-829b-45217bd286be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (7827, 493)\n",
      "Calculating Risk/Opportunity Scores...\n",
      "Scoring complete.\n",
      "Data shape after dropping NaNs and scoring: (698, 499)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ static_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">242</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ ts_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> │ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,600</span> │ ts_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">612</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ static_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m242\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ ts_input (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m2\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m31,104\u001b[0m │ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │          \u001b[38;5;34m10,600\u001b[0m │ ts_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │           \u001b[38;5;34m1,020\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │           \u001b[38;5;34m1,300\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │           \u001b[38;5;34m2,050\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                │             \u001b[38;5;34m612\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,942</span> (214.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,942\u001b[0m (214.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,942</span> (214.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,942\u001b[0m (214.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n",
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.9525 - mae: 0.5845 - val_loss: 0.5734 - val_mae: 0.4805\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4446 - mae: 0.5039 - val_loss: 35.2920 - val_mae: 1.0903\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 868.3898 - mae: 2.8387 - val_loss: 0.4514 - val_mae: 0.3434\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7215 - mae: 0.3699 - val_loss: 0.4643 - val_mae: 0.3335\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7201 - mae: 0.3373 - val_loss: 0.4450 - val_mae: 0.3172\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7891 - mae: 0.3480 - val_loss: 0.4194 - val_mae: 0.3007\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4399 - mae: 0.2862 - val_loss: 0.3891 - val_mae: 0.2849\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5057 - mae: 0.2689 - val_loss: 0.3499 - val_mae: 0.2664\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4961 - mae: 0.2875 - val_loss: 0.2950 - val_mae: 0.2473\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6349 - mae: 0.3020 - val_loss: 0.1991 - val_mae: 0.2042\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2637 - mae: 0.2144 - val_loss: 0.1271 - val_mae: 0.1775\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1968 - mae: 0.1982 - val_loss: 0.1162 - val_mae: 0.1730\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2135 - mae: 0.1897 - val_loss: 0.1071 - val_mae: 0.1585\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1216 - mae: 0.1589 - val_loss: 0.1129 - val_mae: 0.1592\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1691 - mae: 0.1676 - val_loss: 0.1259 - val_mae: 0.1802\n",
      "Epoch 16/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2068 - mae: 0.1951 - val_loss: 0.1207 - val_mae: 0.1692\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1645 - mae: 0.1714 - val_loss: 0.1127 - val_mae: 0.1597\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1079 - mae: 0.1567 - val_loss: 0.1120 - val_mae: 0.1526\n",
      "Epoch 19/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1784 - mae: 0.1586 - val_loss: 0.1227 - val_mae: 0.1662\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1154 - mae: 0.1479 - val_loss: 0.1203 - val_mae: 0.1587\n",
      "Epoch 21/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1387 - mae: 0.1533 - val_loss: 0.1185 - val_mae: 0.1584\n",
      "Epoch 22/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1282 - mae: 0.1461 - val_loss: 0.1555 - val_mae: 0.1708\n",
      "Epoch 23/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1474 - mae: 0.1599 - val_loss: 0.1194 - val_mae: 0.1600\n",
      "Epoch 24/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1188 - mae: 0.1384 - val_loss: 0.1130 - val_mae: 0.1524\n",
      "Epoch 25/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1032 - mae: 0.1374 - val_loss: 0.1336 - val_mae: 0.1631\n",
      "Epoch 26/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1448 - mae: 0.1594 - val_loss: 0.1084 - val_mae: 0.1476\n",
      "Epoch 27/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0954 - mae: 0.1307 - val_loss: 0.1147 - val_mae: 0.1465\n",
      "Epoch 28/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1233 - mae: 0.1385 - val_loss: 0.1173 - val_mae: 0.1529\n",
      "Epoch 29/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0796 - mae: 0.1303 - val_loss: 0.1092 - val_mae: 0.1439\n",
      "Epoch 30/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1084 - mae: 0.1513 - val_loss: 0.1190 - val_mae: 0.1472\n",
      "Epoch 31/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.0411 - mae: 0.2561 - val_loss: 0.1828 - val_mae: 0.2117\n",
      "Epoch 32/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4029 - mae: 0.2427 - val_loss: 0.1102 - val_mae: 0.1775\n",
      "Epoch 33/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1003 - mae: 0.1431 - val_loss: 0.1007 - val_mae: 0.1423\n",
      "Epoch 34/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0979 - mae: 0.1384 - val_loss: 0.0950 - val_mae: 0.1401\n",
      "Epoch 35/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1103 - mae: 0.1356 - val_loss: 0.0987 - val_mae: 0.1423\n",
      "Epoch 36/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0796 - mae: 0.1305 - val_loss: 0.1057 - val_mae: 0.1456\n",
      "Epoch 37/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1412 - mae: 0.1469 - val_loss: 0.0892 - val_mae: 0.1291\n",
      "Epoch 38/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0991 - mae: 0.1318 - val_loss: 0.0815 - val_mae: 0.1275\n",
      "Epoch 39/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0621 - mae: 0.1125 - val_loss: 0.0903 - val_mae: 0.1312\n",
      "Epoch 40/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1071 - mae: 0.1369 - val_loss: 0.0732 - val_mae: 0.1250\n",
      "Epoch 41/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0956 - mae: 0.1228 - val_loss: 0.0698 - val_mae: 0.1301\n",
      "Epoch 42/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0685 - mae: 0.1194 - val_loss: 0.0747 - val_mae: 0.1295\n",
      "Epoch 43/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.7339 - mae: 0.1745 - val_loss: 0.3148 - val_mae: 0.3260\n",
      "Epoch 44/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2601 - mae: 0.2900 - val_loss: 0.1333 - val_mae: 0.1730\n",
      "Epoch 45/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0907 - mae: 0.1525 - val_loss: 0.1162 - val_mae: 0.1635\n",
      "Epoch 46/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1162 - mae: 0.1482 - val_loss: 0.1325 - val_mae: 0.1620\n",
      "Epoch 47/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1113 - mae: 0.1386 - val_loss: 0.1134 - val_mae: 0.1496\n",
      "Epoch 48/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1057 - mae: 0.1356 - val_loss: 0.1004 - val_mae: 0.1402\n",
      "Epoch 49/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0641 - mae: 0.1104 - val_loss: 0.0956 - val_mae: 0.1363\n",
      "Epoch 50/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1192 - mae: 0.1359 - val_loss: 0.1033 - val_mae: 0.1417\n",
      "Training complete.\n",
      "\n",
      "Model evaluated on test set.\n",
      "Test Mean Squared Error (Loss): 0.10\n",
      "Test Mean Absolute Error (scaled): 0.14\n",
      "\n",
      "Running an example prediction...\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "Example Region:\n",
      "RegionName                 32825\n",
      "STATE                         FL\n",
      "CountyName_zhvi    Orange County\n",
      "Name: 446, dtype: object\n",
      "\n",
      "--- Risk & Opportunity Scores ---\n",
      "  Overall Score: 61.9 (Grade: D)\n",
      "   Safety Score: 55.0 (Grade: F)\n",
      "   School Score: 72.4 (Grade: C)\n",
      "\n",
      "--- Predicted vs. Actual 12-Month Price Forecast ---\n",
      "    Month  Predicted_Price  Actual_Price  Difference\n",
      "0       1           240121        247868       -7747\n",
      "1       2           247845        249459       -1614\n",
      "2       3           254822        250876        3946\n",
      "3       4           252645        251748         897\n",
      "4       5           256242        252178        4064\n",
      "5       6           248685        252486       -3801\n",
      "6       7           244180        252977       -8797\n",
      "7       8           241392        253337      -11945\n",
      "8       9           254960        253614        1346\n",
      "9      10           248192        254106       -5914\n",
      "10     11           244478        255122      -10644\n",
      "11     12           261808        256670        5138\n",
      "\n",
      "Test Mean Absolute Error (in dollars): $59,879.36\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Suppress TensorFlow logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "def create_sequences(ts_data, n_past, n_future):\n",
    "    \"\"\"\n",
    "    Creates sequences for time-series forecasting.\n",
    "    ts_data: Numpy array of time-series features\n",
    "    n_past: Number of past months to use as input\n",
    "    n_future: Number of future months to predict\n",
    "    \"\"\"\n",
    "    X_ts, y_ts = [], []\n",
    "    for i in range(n_past, len(ts_data.columns) - n_future + 1):\n",
    "        X_ts.append(ts_data.iloc[:, i - n_past:i].values)\n",
    "        y_ts.append(ts_data.iloc[:, i:i + n_future].values)\n",
    "    \n",
    "    # This is a simplified example; for a real model, we'd need\n",
    "    # to handle the sequence creation per-row and align it.\n",
    "    # For this PoC, we will reshape the data directly.\n",
    "    pass # See main() for the actual data prep logic\n",
    "\n",
    "def build_forecasting_model(n_past_steps, n_features_ts, n_static_features, n_future_steps):\n",
    "    \"\"\"\n",
    "    Defines the Keras Multi-Input Functional Model.\n",
    "    \"\"\"\n",
    "    # --- Time-Series Input Path (LSTM) ---\n",
    "    # This branch handles the historical price/rent sequences\n",
    "    ts_input = Input(shape=(n_past_steps, n_features_ts), name='ts_input')\n",
    "    lstm_layer = LSTM(50, activation='relu', return_sequences=False)(ts_input)\n",
    "    lstm_out = Dropout(0.2)(lstm_layer)\n",
    "    ts_dense = Dense(20, activation='relu')(lstm_out)\n",
    "\n",
    "    # --- Static Data Input Path (Dense) ---\n",
    "    # This branch handles crime, population, school scores, etc.\n",
    "    static_input = Input(shape=(n_static_features,), name='static_input')\n",
    "    dense_layer = Dense(128, activation='relu')(static_input)\n",
    "    dense_out = Dropout(0.2)(dense_layer)\n",
    "    dense_layer = Dense(64, activation='relu')(dense_out)\n",
    "    static_dense = Dense(20, activation='relu')(dense_layer)\n",
    "\n",
    "    # --- Concatenate Paths ---\n",
    "    # Combine the wisdom from both branches\n",
    "    combined = concatenate([ts_dense, static_dense])\n",
    "    \n",
    "    # --- Final Layers ---\n",
    "    final_dense = Dense(50, activation='relu')(combined)\n",
    "    \n",
    "    # --- Output Layer ---\n",
    "    # We want N neurons to predict the next N steps (e.g., 12 months)\n",
    "    output = Dense(n_future_steps, activation='linear', name='output')(final_dense)\n",
    "    \n",
    "    # --- Build and Compile ---\n",
    "    model = Model(inputs=[ts_input, static_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_letter_grade(score):\n",
    "    \"\"\"Converts a 0-100 score to a letter grade.\"\"\"\n",
    "    if score >= 90: return 'A'\n",
    "    if score >= 80: return 'B'\n",
    "    if score >= 70: return 'C'\n",
    "    if score >= 60: return 'D'\n",
    "    return 'F'\n",
    "\n",
    "def calculate_scores(df):\n",
    "    \"\"\"\n",
    "    Engineers 'Safety' and 'School' scores (0-100) and letter grades.\n",
    "    This function modifies the DataFrame in place.\n",
    "    \"\"\"\n",
    "    print(\"Calculating Risk/Opportunity Scores...\")\n",
    "    \n",
    "    # --- 1. Safety Score (Lower is better) ---\n",
    "    # We use 'crime_rate_per_100000'\n",
    "    # We'll use quantiles: top 20% (lowest crime) get an A, bottom 20% get an F\n",
    "    df['Safety_Score'] = pd.qcut(df['crime_rate_per_100000'],\n",
    "                                 q=[0, .2, .4, .6, .8, 1.],\n",
    "                                 labels=[95, 85, 75, 65, 55]).astype(float)\n",
    "    # A simplified quantile scoring: 95 = A (top 20% safest), 55 = F (bottom 20%)\n",
    "    \n",
    "    # --- 2. School Score (Higher is better) ---\n",
    "    # We'll use 'CountySchoolScore_y' and 'Proficiency'\n",
    "    # Normalize both from 0-1 using min-max (robust to outliers)\n",
    "    prof_min, prof_max = df['Proficiency'].min(), df['Proficiency'].max()\n",
    "    school_min, school_max = df['CountySchoolScore_y'].min(), df['CountySchoolScore_y'].max()\n",
    "\n",
    "    df['Proficiency_norm'] = (df['Proficiency'] - prof_min) / (prof_max - prof_min)\n",
    "    df['SchoolScore_norm'] = (df['CountySchoolScore_y'] - school_min) / (school_max - school_min)\n",
    "    \n",
    "    # Combine them (e.g., 50/50 weights) and scale to 100\n",
    "    df['School_Score'] = (0.5 * df['Proficiency_norm'] + 0.5 * df['SchoolScore_norm']) * 100\n",
    "    \n",
    "    # --- 3. Overall Score ---\n",
    "    # We can create a weighted average, e.g., 60% Safety, 40% Schools\n",
    "    df['Overall_Score'] = (0.6 * df['Safety_Score']) + (0.4 * df['School_Score'])\n",
    "    \n",
    "    # --- 4. Add Letter Grades ---\n",
    "    df['Safety_Grade'] = df['Safety_Score'].apply(get_letter_grade)\n",
    "    df['School_Grade'] = df['School_Score'].apply(get_letter_grade)\n",
    "    df['Overall_Grade'] = df['Overall_Score'].apply(get_letter_grade)\n",
    "    \n",
    "    # Drop intermediate columns\n",
    "    df.drop(['Proficiency_norm', 'SchoolScore_norm'], axis=1, inplace=True)\n",
    "    \n",
    "    print(\"Scoring complete.\")\n",
    "    return df\n",
    "\n",
    "def find_date_columns(all_columns):\n",
    "    \"\"\"\n",
    "    Identifies date-based columns (e.g., '1/31/2000' or '2015-01-31_zhvi')\n",
    "    \"\"\"\n",
    "    # Regex to find 'YYYY-MM-DD_zhvi' or 'MM/DD/YYYY'\n",
    "    date_regex = re.compile(r'(\\d{4}-\\d{2}-\\d{2}_zhvi|\\d{1,2}/\\d{1,2}/\\d{4})')\n",
    "    zhvi_cols = sorted([col for col in all_columns if date_regex.match(col) and '_zhvi' in col])\n",
    "    zori_cols = sorted([col for col in all_columns if date_regex.match(col) and '_zori' in col])\n",
    "    \n",
    "    # Simpler regex if the above fails\n",
    "    if not zhvi_cols:\n",
    "         date_regex_simple = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{4}$')\n",
    "         zhvi_cols = sorted([col for col in all_columns if date_regex_simple.match(col)])\n",
    "         \n",
    "    # Assuming zori columns are not present if zhvi fails to be found\n",
    "    # This is a simplification; a real implementation would need robust column mapping\n",
    "    \n",
    "    # For this demo, we'll assume the simple M/D/YYYY format was found\n",
    "    if not zori_cols and zhvi_cols:\n",
    "        # Create dummy zori cols for the sake of model architecture\n",
    "        # In a real case, you'd find the real '..._zori' cols\n",
    "        zori_cols = zhvi_cols \n",
    "        \n",
    "    return zhvi_cols, zori_cols\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- 1. Data Ingestion ---\n",
    "    try:\n",
    "        data = pd.read_csv('final_with_proficiency.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'final_with_proficiency.csv' not found.\")\n",
    "        return\n",
    "        \n",
    "    # --- NEW: Strip whitespace from column names ---\n",
    "    data.columns = data.columns.str.strip()\n",
    "        \n",
    "    print(f\"Original data shape: {data.shape}\")\n",
    "\n",
    "    # --- 2. Feature & Target Definition ---\n",
    "    \n",
    "    # --- 2a. Static (Non-Time-Series) Features ---\n",
    "    # These features are constant for each region\n",
    "    categorical_static_features = ['STATE', 'Metro_zhvi', 'CountyName_zhvi']\n",
    "    numerical_static_features = [\n",
    "        'SizeRank_zhvi', 'latest_rent', 'crime_rate_per_100000', \n",
    "        'population', 'CountySchoolScore_y', 'Proficiency'\n",
    "    ]\n",
    "    static_features = categorical_static_features + numerical_static_features\n",
    "\n",
    "    # --- 2b. Time-Series (Sequential) Features ---\n",
    "    # We need to find all the date columns for home value and rent\n",
    "    all_cols = data.columns.tolist()\n",
    "    \n",
    "    # --- REVISED DATE-FINDING LOGIC ---\n",
    "    # We will use data from 2015 onwards, where we have both ZHVI (price) and ZORI (rent)\n",
    "    \n",
    "    # Regex to find 'YYYY-MM-DD_zhvi' and 'YYYY-MM-DD_zori'\n",
    "    date_regex_zhvi = re.compile(r'^\\d{4}-\\d{2}-\\d{2}_zhvi$')\n",
    "    date_regex_zori = re.compile(r'^\\d{4}-\\d{2}-\\d{2}_zori$')\n",
    "\n",
    "    # Find all matching columns and sort them chronologically\n",
    "    zhvi_cols = sorted([col for col in all_cols if date_regex_zhvi.match(col)])\n",
    "    zori_cols = sorted([col for col in all_cols if date_regex_zori.match(col)])\n",
    "    \n",
    "    # Ensure we have the same number of rent and price columns\n",
    "    if len(zhvi_cols) != len(zori_cols):\n",
    "        print(f\"Warning: Mismatched time-series columns. Found {len(zhvi_cols)} price cols\" +\n",
    "              f\" and {len(zori_cols)} rent cols. Using common subset.\")\n",
    "        \n",
    "        # Find the common set of dates (e.g., '2015-01-31')\n",
    "        zhvi_dates = {col.split('_')[0] for col in zhvi_cols}\n",
    "        zori_dates = {col.split('_')[0] for col in zori_cols}\n",
    "        common_dates = sorted(list(zhvi_dates.intersection(zori_dates)))\n",
    "        \n",
    "        zhvi_cols = [f\"{date}_zhvi\" for date in common_dates]\n",
    "        zori_cols = [f\"{date}_zori\" for date in common_dates]\n",
    "\n",
    "    if len(zhvi_cols) < 60:\n",
    "        print(f\"Error: Found only {len(zhvi_cols)} time-series columns. Need at least 60 (5 years) for this model.\")\n",
    "        return\n",
    "    # --- END REVISED LOGIC ---\n",
    "\n",
    "    # --- 2c. Define Model Time Steps ---\n",
    "    N_PAST = 48    # Use 48 months (4 years) of history\n",
    "    N_FUTURE = 12  # Predict the next 12 months (1 year)\n",
    "    \n",
    "    # Ensure we have enough data\n",
    "    if len(zhvi_cols) < N_PAST + N_FUTURE:\n",
    "        print(f\"Error: Not enough date columns ({len(zhvi_cols)}) for {N_PAST} past and {N_FUTURE} future steps.\")\n",
    "        return\n",
    "        \n",
    "    # We need 48 + 12 = 60 months of data\n",
    "    ts_cols_zhvi = zhvi_cols[:N_PAST + N_FUTURE]\n",
    "    ts_cols_zori = zori_cols[:N_PAST + N_FUTURE]\n",
    "    \n",
    "    # --- MODEL UPGRADE: Use 2 Time-Series Features (Price and Rent) ---\n",
    "    N_FEATURES_TS = 2 \n",
    "    \n",
    "    # Define our time-series inputs (X_ts) and targets (y)\n",
    "    # X_ts: We use *both* price and rent history\n",
    "    X_ts_data_zhvi = data[ts_cols_zhvi[:N_PAST]]\n",
    "    X_ts_data_zori = data[ts_cols_zori[:N_PAST]]\n",
    "    \n",
    "    # y: We are only forecasting the *price* (zhvi)\n",
    "    y_data = data[ts_cols_zhvi[N_PAST:N_PAST + N_FUTURE]]\n",
    "\n",
    "    # --- 3. Preprocessing ---\n",
    "    \n",
    "    # --- 3a. Handle Missing Data ---\n",
    "    # Drop rows where any of our selected columns are NaN\n",
    "    all_features_to_check = static_features + ts_cols_zhvi + ts_cols_zori\n",
    "    data.dropna(subset=all_features_to_check, inplace=True)\n",
    "    \n",
    "    # --- NEW: Calculate Scores ---\n",
    "    # This function adds new columns (e.g., 'Safety_Score', 'Overall_Grade')\n",
    "    # We do this *after* dropping NaNs to ensure we only score valid rows\n",
    "    data = calculate_scores(data)\n",
    "    \n",
    "    # Re-align data after dropping NaNs\n",
    "    X_ts_data_zhvi = data[ts_cols_zhvi[:N_PAST]]\n",
    "    X_ts_data_zori = data[ts_cols_zori[:N_PAST]]\n",
    "    y_data = data[ts_cols_zhvi[N_PAST:N_PAST + N_FUTURE]]\n",
    "    X_static_data = data[static_features] # <-- FIX: This line was missing\n",
    "    \n",
    "    print(f\"Data shape after dropping NaNs and scoring: {data.shape}\")\n",
    "    if data.shape[0] == 0:\n",
    "        print(\"Error: No data remaining after dropping NaNs.\")\n",
    "        return\n",
    "\n",
    "    # --- 3b. Preprocessing Static Features ---\n",
    "    # We need to scale numericals and one-hot encode categoricals\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    static_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_static_features),\n",
    "            ('cat', categorical_transformer, categorical_static_features)\n",
    "        ])\n",
    "\n",
    "    # --- 3c. Preprocessing Time-Series Features ---\n",
    "    # We need to scale the time-series data as well\n",
    "    ts_scaler_zhvi = StandardScaler()\n",
    "    ts_scaler_zori = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "    \n",
    "    # Fit scalers on the full TS dataset (before train/test split)\n",
    "    # This is a simplification; fitting only on train data is better practice\n",
    "    X_ts_data_zhvi_scaled = ts_scaler_zhvi.fit_transform(X_ts_data_zhvi)\n",
    "    X_ts_data_zori_scaled = ts_scaler_zori.fit_transform(X_ts_data_zori)\n",
    "    \n",
    "    y_data_scaled = y_scaler.fit_transform(y_data)\n",
    "    \n",
    "    # --- STACK TS FEATURES ---\n",
    "    # Stack the 2 features (price and rent) into one array\n",
    "    X_ts_data_scaled = np.stack([X_ts_data_zhvi_scaled, X_ts_data_zori_scaled], axis=-1)\n",
    "\n",
    "    # --- 4. Train/Test Split ---\n",
    "    # We split all our data on the same index\n",
    "    indices = np.arange(data.shape[0])\n",
    "    \n",
    "    (X_static_train_df, X_static_test_df,\n",
    "     X_ts_train_scaled, X_ts_test_scaled,\n",
    "     y_train_scaled, y_test_scaled,\n",
    "     y_train_unscaled, y_test_unscaled, # <-- FIX: Was missing y_train_unscaled\n",
    "     indices_train, indices_test) = train_test_split(\n",
    "        X_static_data,\n",
    "        X_ts_data_scaled,\n",
    "        y_data_scaled,\n",
    "        y_data, # Original unscaled y\n",
    "        indices,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # --- 5. Apply Static Preprocessing ---\n",
    "    # Fit the preprocessor on the training data *only*\n",
    "    X_static_train = static_preprocessor.fit_transform(X_static_train_df)\n",
    "    # Transform the test data\n",
    "    X_static_test = static_preprocessor.transform(X_static_test_df)\n",
    "    \n",
    "    # --- 6. Reshape TS Data for LSTM ---\n",
    "    # LSTM needs input as [samples, timesteps, features]\n",
    "    # Our data is already [samples, timesteps, features] after np.stack\n",
    "    X_ts_train_reshaped = X_ts_train_scaled\n",
    "    X_ts_test_reshaped = X_ts_test_scaled\n",
    "    \n",
    "    N_STATIC_FEATURES = X_static_train.shape[1]\n",
    "\n",
    "    # --- 7. Model Definition ---\n",
    "    model = build_forecasting_model(N_PAST, N_FEATURES_TS, N_STATIC_FEATURES, N_FUTURE)\n",
    "    model.summary()\n",
    "\n",
    "    # --- 8. Model Training ---\n",
    "    print(\"\\nStarting model training...\")\n",
    "    history = model.fit(\n",
    "        [X_ts_train_reshaped, X_static_train], # List of inputs\n",
    "        y_train_scaled,\n",
    "        validation_data=([X_ts_test_reshaped, X_static_test], y_test_scaled),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # --- 9. Model Evaluation ---\n",
    "    test_loss, test_mae = model.evaluate([X_ts_test_reshaped, X_static_test], y_test_scaled, verbose=0)\n",
    "    print(f\"\\nModel evaluated on test set.\")\n",
    "    print(f\"Test Mean Squared Error (Loss): {test_loss:.2f}\")\n",
    "    print(f\"Test Mean Absolute Error (scaled): {test_mae:.2f}\")\n",
    "    \n",
    "    # --- 10. Example Prediction (Interpretable) ---\n",
    "    print(\"\\nRunning an example prediction...\")\n",
    "    \n",
    "    # Get predictions (scaled)\n",
    "    y_pred_scaled = model.predict([X_ts_test_reshaped, X_static_test])\n",
    "    \n",
    "    # Inverse transform to get actual dollar values\n",
    "    y_pred_unscaled = y_scaler.inverse_transform(y_pred_scaled)\n",
    "    \n",
    "    # Compare first prediction in test set\n",
    "    predicted_forecast_12mo = y_pred_unscaled[0]\n",
    "    actual_forecast_12mo = y_test_unscaled.iloc[0].values\n",
    "    \n",
    "    print(\"\\nExample Region:\")\n",
    "    # Get the original row of data for the first test sample\n",
    "    example_region_data = data.iloc[indices_test[0]]\n",
    "    print(example_region_data[['RegionName', 'STATE', 'CountyName_zhvi']])\n",
    "    \n",
    "    print(\"\\n--- Risk & Opportunity Scores ---\")\n",
    "    print(f\"  Overall Score: {example_region_data['Overall_Score']:.1f} (Grade: {example_region_data['Overall_Grade']})\")\n",
    "    print(f\"   Safety Score: {example_region_data['Safety_Score']:.1f} (Grade: {example_region_data['Safety_Grade']})\")\n",
    "    print(f\"   School Score: {example_region_data['School_Score']:.1f} (Grade: {example_region_data['School_Grade']})\")\n",
    "    \n",
    "    print(\"\\n--- Predicted vs. Actual 12-Month Price Forecast ---\")\n",
    "    comparison = pd.DataFrame({\n",
    "        'Month': range(1, N_FUTURE + 1),\n",
    "        'Predicted_Price': predicted_forecast_12mo.astype(int),\n",
    "        'Actual_Price': actual_forecast_12mo.astype(int)\n",
    "    })\n",
    "    comparison['Difference'] = comparison['Predicted_Price'] - comparison['Actual_Price']\n",
    "    \n",
    "    print(comparison)\n",
    "    \n",
    "    # Calculate final, interpretable MAE in dollars\n",
    "    final_mae = np.mean(np.abs(y_pred_unscaled - y_test_unscaled.values))\n",
    "    print(f\"\\nTest Mean Absolute Error (in dollars): ${final_mae:,.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
